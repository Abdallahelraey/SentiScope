{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\AI\\\\NLP\\\\HandsOn\\\\sentiment-analysis'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"../\")\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from typing import Dict, List, Tuple, Union, Optional, Any\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class ModelDevelopmentConfig:\n",
    "    root_dir: Path\n",
    "    data_files_path: Path\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class TrainingResult:\n",
    "    \"\"\"Container for training results\"\"\"\n",
    "    model_name: str\n",
    "    metrics: Dict[str, float]\n",
    "    predictions: np.ndarray\n",
    "    parameters: Dict[str, Any]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SentiScope.constants import (CONFIG_FILE_PATH,\n",
    "                                  PARAMS_FILE_PATH)\n",
    "from SentiScope.utils.file_utils import (create_directories,\n",
    "                                            get_size)\n",
    "from SentiScope.utils.config_utils import (read_yaml,\n",
    "                                           Settings,\n",
    "                                           get_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        create_directories([self.config.artifacts_root])\n",
    "        \n",
    "    def get_latest_report(self) -> Dict:\n",
    "        \"\"\"Locate the latest metadata.json file based on the timestamp folder.\"\"\"\n",
    "        config = self.config.feature_transformation\n",
    "        profiling_dir = Path(config.root_dir)\n",
    "\n",
    "        # Get all subdirectories in data_profiling\n",
    "        timestamp_dirs = [d for d in profiling_dir.iterdir() if d.is_dir()]\n",
    "        \n",
    "        if not timestamp_dirs:\n",
    "            raise FileNotFoundError(\"No timestamp folders found in feature_transformation.\")\n",
    "\n",
    "        # Sort directories by name (assuming timestamp format)\n",
    "        latest_dir = sorted(timestamp_dirs, key=lambda x: x.name, reverse=True)[0]\n",
    "        metadata_path = latest_dir / \"metadata.json\"\n",
    "\n",
    "        if not metadata_path.exists():\n",
    "            raise FileNotFoundError(f\"metadata.json not found in {latest_dir}.\")\n",
    "\n",
    "        # Load the report.json file\n",
    "        with open(metadata_path, \"r\") as f:\n",
    "            report_data = json.load(f)\n",
    "\n",
    "        return report_data\n",
    "\n",
    "    def get_model_development_config(self) -> ModelDevelopmentConfig:\n",
    "        config = self.config.model_development\n",
    "        report_data = self.get_latest_report()\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        timestamp = report_data[\"timestamp\"]\n",
    "        # data_file_path = Path(str(config.data_file).format(timestamp=timestamp))\n",
    "        data_files_path = Path(config.data_files_path).joinpath(f\"{timestamp}\")\n",
    " \n",
    "\n",
    "        model_development_config = ModelDevelopmentConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            data_files_path=data_files_path,\n",
    "\n",
    "        )\n",
    "\n",
    "        return model_development_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from typing import Dict, Any\n",
    "import numpy as np\n",
    "\n",
    "class BaseModel(ABC):\n",
    "    \"\"\"Abstract base class defining the interface for all models\"\"\"\n",
    "    \n",
    "    @abstractmethod\n",
    "    def train(self, X_train: Any, y_train: Any) -> None:\n",
    "        \"\"\"Train the model on the given data\"\"\"\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def predict(self, X: Any) -> np.ndarray:\n",
    "        \"\"\"Make predictions on new data\"\"\"\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def get_params(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get the model's current parameters\"\"\"\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def set_params(self, **params) -> None:\n",
    "        \"\"\"Set the model's parameters\"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "class SklearnModelWrapper(BaseModel):\n",
    "    \"\"\"Wrapper for scikit-learn models to conform to our interface\"\"\"\n",
    "    \n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "    \n",
    "    def train(self, X_train, y_train):\n",
    "        return self.model.fit(X_train, y_train)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)\n",
    "    \n",
    "    def get_params(self):\n",
    "        return self.model.get_params()\n",
    "    \n",
    "    def set_params(self, **params):\n",
    "        return self.model.set_params(**params)\n",
    "\n",
    "class LogisticRegressionModel(SklearnModelWrapper):\n",
    "    \"\"\"Logistic Regression implementation\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__(LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000))\n",
    "\n",
    "class SVMModel(SklearnModelWrapper):\n",
    "    \"\"\"Support Vector Machine implementation\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__(SVC(kernel='linear', probability=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Dict, Any, List\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "from scipy.sparse import issparse\n",
    "from scipy import sparse\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "from SentiScope.logging import logger\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "class TrainingManager:\n",
    "    \"\"\"Handles model training and evaluation\"\"\"\n",
    "    \n",
    "    def __init__(self, output_dir: Path):\n",
    "        self.training_history: List[TrainingResult] = []\n",
    "        self.output_dir = output_dir\n",
    "        logger.info(f\"Initialized TrainingManager with output directory: {output_dir}\")\n",
    "    \n",
    "    def _validate_data_split(self, data_split):\n",
    "        \"\"\"Validate the data split dictionary\"\"\"\n",
    "        logger.info(\"Validating data split...\")\n",
    "        \n",
    "        if not isinstance(data_split, dict):\n",
    "            msg = f\"data_split must be a dictionary, got {type(data_split)}\"\n",
    "            logger.error(msg)\n",
    "            raise TypeError(msg)\n",
    "            \n",
    "        required_keys = [\"X_train\", \"X_test\", \"y_train\", \"y_test\"]\n",
    "        \n",
    "        missing = [key for key in required_keys if key not in data_split]\n",
    "        if missing:\n",
    "            msg = f\"Missing required keys in data_split: {missing}\"\n",
    "            logger.error(msg)\n",
    "            raise ValueError(msg)\n",
    "        \n",
    "        n_train_samples = (data_split[\"X_train\"].shape[0] if not issparse(data_split[\"X_train\"]) \n",
    "                          else data_split[\"X_train\"].shape[0])\n",
    "        n_test_samples = (data_split[\"X_test\"].shape[0] if not issparse(data_split[\"X_test\"]) \n",
    "                         else data_split[\"X_test\"].shape[0])\n",
    "        \n",
    "        if n_train_samples != len(data_split[\"y_train\"]):\n",
    "            msg = (f\"Mismatch in training set dimensions: X_train has {n_train_samples} \"\n",
    "                  f\"samples but y_train has {len(data_split['y_train'])} samples\")\n",
    "            logger.error(msg)\n",
    "            raise ValueError(msg)\n",
    "        \n",
    "        if n_test_samples != len(data_split[\"y_test\"]):\n",
    "            msg = (f\"Mismatch in test set dimensions: X_test has {n_test_samples} \"\n",
    "                  f\"samples but y_test has {len(data_split['y_test'])} samples\")\n",
    "            logger.error(msg)\n",
    "            raise ValueError(msg)\n",
    "        \n",
    "        logger.info(\"Data split validation completed successfully\")\n",
    "    \n",
    "    def train_and_evaluate(self, model, model_name: str, data_split) -> TrainingResult:\n",
    "        \"\"\"Train a model and evaluate its performance\"\"\"\n",
    "        try:\n",
    "            logger.info(f\"Starting training and evaluation for {model_name}\")\n",
    "            \n",
    "            # Validate the data split\n",
    "            self._validate_data_split(data_split)\n",
    "            \n",
    "            # Verify model has required methods\n",
    "            required_methods = ['train', 'predict', 'get_params']\n",
    "            for method in required_methods:\n",
    "                if not hasattr(model, method):\n",
    "                    msg = f\"Model lacks required method: {method}\"\n",
    "                    logger.error(msg)\n",
    "                    raise AttributeError(msg)\n",
    "            \n",
    "            # Train the model\n",
    "            logger.info(f\"Training {model_name}...\")\n",
    "            model.train(data_split[\"X_train\"], data_split[\"y_train\"])\n",
    "            \n",
    "            # Make predictions\n",
    "            logger.info(f\"Making predictions for {model_name}...\")\n",
    "            predictions = model.predict(data_split[\"X_test\"])\n",
    "            \n",
    "            # Calculate metrics\n",
    "            logger.info(f\"Calculating metrics for {model_name}...\")\n",
    "            metrics = classification_report(\n",
    "                data_split[\"y_test\"], \n",
    "                predictions, \n",
    "                output_dict=True\n",
    "            )\n",
    "            \n",
    "            # Create result object\n",
    "            result = TrainingResult(\n",
    "                model_name=model_name,\n",
    "                metrics=metrics,\n",
    "                predictions=predictions,\n",
    "                parameters=model.get_params()\n",
    "            )\n",
    "            \n",
    "            # Save results to output directory\n",
    "            model_dir = self.output_dir / model_name\n",
    "            model_dir.mkdir(exist_ok=True)\n",
    "            \n",
    "            # Save predictions\n",
    "            np.save(model_dir / 'predictions.npy', predictions)\n",
    "            \n",
    "            # Save metrics and parameters\n",
    "            with open(model_dir / 'results.json', 'w') as f:\n",
    "                json.dump({\n",
    "                    'metrics': metrics,\n",
    "                    'parameters': model.get_params()\n",
    "                }, f, indent=4)\n",
    "            \n",
    "            self.training_history.append(result)\n",
    "            \n",
    "            logger.info(f\"Successfully completed training and evaluation for {model_name}\")\n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in train_and_evaluate for {model_name}: {str(e)}\")\n",
    "            raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SentimentPipeline:\n",
    "    \"\"\"Coordinates all components of the sentiment analysis system\"\"\"\n",
    "    \n",
    "    def __init__(self, config: ModelDevelopmentConfig):\n",
    "        self.config = config\n",
    "        self.data_files_path = self.config.data_files_path\n",
    "        \n",
    "        # Create timestamped output directory\n",
    "        self.timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        self.output_dir = Path(self.config.root_dir) / self.timestamp\n",
    "        self.output_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        self.training_manager = TrainingManager(self.output_dir)\n",
    "        self.models = {\n",
    "            'logistic_regression': LogisticRegressionModel()\n",
    "        }\n",
    "        \n",
    "        logger.info(f\"Initialized SentimentPipeline with output directory: {self.output_dir}\")\n",
    "    \n",
    "    def prepare_data(self):\n",
    "        \"\"\"Load and prepare data for training\"\"\"\n",
    "        try:\n",
    "            logger.info(\"Loading prepared data from artifacts...\")\n",
    "            \n",
    "            # Construct paths to the data files\n",
    "            x_train_path = self.data_files_path / \"X_train.npy\"\n",
    "            x_test_path = self.data_files_path / \"X_test.npy\"\n",
    "            y_train_path = self.data_files_path / \"y_train.npy\"\n",
    "            y_test_path = self.data_files_path / \"y_test.npy\"\n",
    "\n",
    "            # Load the data\n",
    "            X_train_npy = np.load(x_train_path, allow_pickle=True)\n",
    "            X_test_npy = np.load(x_test_path, allow_pickle=True)\n",
    "            y_train = np.load(y_train_path, allow_pickle=True)\n",
    "            y_test = np.load(y_test_path, allow_pickle=True)\n",
    "            \n",
    "            # Convert to sparse matrices\n",
    "            X_train_sparse = sparse.csr_matrix(X_train_npy.all())\n",
    "            X_test_sparse = sparse.csr_matrix(X_test_npy.all())\n",
    "\n",
    "            logger.info(\"Data successfully loaded and converted to sparse format\")\n",
    "            \n",
    "            # Save data info to metadata\n",
    "            metadata = {\n",
    "                'timestamp': self.timestamp,\n",
    "                'data_shapes': {\n",
    "                    'X_train': X_train_sparse.shape,\n",
    "                    'X_test': X_test_sparse.shape,\n",
    "                    'y_train': y_train.shape,\n",
    "                    'y_test': y_test.shape\n",
    "                },\n",
    "                'data_source': {\n",
    "                    'X_train': str(x_train_path),\n",
    "                    'X_test': str(x_test_path),\n",
    "                    'y_train': str(y_train_path),\n",
    "                    'y_test': str(y_test_path)\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            with open(self.output_dir / 'metadata.json', 'w') as f:\n",
    "                json.dump(metadata, f, indent=4)\n",
    "            \n",
    "            return X_train_sparse, X_test_sparse, y_train, y_test\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error loading data: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    def train_models(self):\n",
    "        \"\"\"Train all registered models\"\"\"\n",
    "        try:\n",
    "            logger.info(\"Starting model training pipeline\")\n",
    "            \n",
    "            x_train, x_test, y_train, y_test = self.prepare_data()\n",
    "            data_split = {\n",
    "                \"X_train\": x_train,\n",
    "                \"X_test\": x_test,\n",
    "                \"y_train\": y_train,\n",
    "                \"y_test\": y_test\n",
    "            }\n",
    "            \n",
    "            results = {}\n",
    "            for name, model in self.models.items():\n",
    "                logger.info(f\"Training model: {name}\")\n",
    "                results[name] = self.training_manager.train_and_evaluate(\n",
    "                    model, name, data_split\n",
    "                )\n",
    "            \n",
    "            # Save final summary\n",
    "            summary = {\n",
    "                'timestamp': self.timestamp,\n",
    "                'models_trained': list(self.models.keys()),\n",
    "                'results': {\n",
    "                    name: {\n",
    "                        'metrics': result.metrics,\n",
    "                        'parameters': result.parameters\n",
    "                    }\n",
    "                    for name, result in results.items()\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            with open(self.output_dir / 'training_summary.json', 'w') as f:\n",
    "                json.dump(summary, f, indent=4)\n",
    "            \n",
    "            logger.info(\"Model training pipeline completed successfully\")\n",
    "            return results\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in train_models: {str(e)}\")\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-01-12 06:54:35,655: INFO: config_utils: yaml file: config\\config.yaml loaded successfully]\n",
      "[2025-01-12 06:54:35,658: INFO: config_utils: yaml file: params.yaml loaded successfully]\n",
      "[2025-01-12 06:54:35,659: INFO: file_utils: created directory at: artifacts]\n",
      "[2025-01-12 06:54:35,661: INFO: file_utils: created directory at: artifacts/model_development]\n",
      "[2025-01-12 06:54:35,663: INFO: 2479361405: Initialized TrainingManager with output directory: artifacts\\model_development\\20250112_065435]\n",
      "[2025-01-12 06:54:35,664: INFO: 233834906: Initialized SentimentPipeline with output directory: artifacts\\model_development\\20250112_065435]\n",
      "[2025-01-12 06:54:35,665: INFO: 233834906: Starting model training pipeline]\n",
      "[2025-01-12 06:54:35,666: INFO: 233834906: Loading prepared data from artifacts...]\n",
      "[2025-01-12 06:54:35,697: INFO: 233834906: Data successfully loaded and converted to sparse format]\n",
      "[2025-01-12 06:54:35,698: INFO: 233834906: Training model: logistic_regression]\n",
      "[2025-01-12 06:54:35,698: INFO: 2479361405: Starting training and evaluation for logistic_regression]\n",
      "[2025-01-12 06:54:35,700: INFO: 2479361405: Validating data split...]\n",
      "[2025-01-12 06:54:35,700: INFO: 2479361405: Data split validation completed successfully]\n",
      "[2025-01-12 06:54:35,701: INFO: 2479361405: Training logistic_regression...]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\AI\\NLP\\HandsOn\\sentiment-analysis\\SentiScope-env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-01-12 06:54:52,215: INFO: 2479361405: Making predictions for logistic_regression...]\n",
      "[2025-01-12 06:54:52,223: INFO: 2479361405: Calculating metrics for logistic_regression...]\n",
      "[2025-01-12 06:54:52,260: INFO: 2479361405: Successfully completed training and evaluation for logistic_regression]\n",
      "[2025-01-12 06:54:52,263: INFO: 233834906: Model training pipeline completed successfully]\n",
      "{'logistic_regression': TrainingResult(model_name='logistic_regression', metrics={'0': {'precision': 0.8866193144218467, 'recall': 0.9321860939746741, 'f1-score': 0.9088319088319088, 'support': 21559.0}, '1': {'precision': 0.8566114933978055, 'recall': 0.8223531512229959, 'f1-score': 0.8391328110766989, 'support': 11202.0}, '2': {'precision': 0.7506227246598965, 'recall': 0.7059830600108128, 'f1-score': 0.7276188707280832, 'support': 11098.0}, 'accuracy': 0.846895734056864, 'macro avg': {'precision': 0.8312845108265162, 'recall': 0.8201741017361609, 'f1-score': 0.8251945302122303, 'support': 43859.0}, 'weighted avg': {'precision': 0.844542710662312, 'recall': 0.846895734056864, 'f1-score': 0.8451762944784097, 'support': 43859.0}}, predictions=array([0, 2, 1, ..., 2, 0, 2]), parameters={'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False})}\n"
     ]
    }
   ],
   "source": [
    "config = ConfigurationManager()\n",
    "model_development_config = config.get_model_development_config()\n",
    "pipeline = SentimentPipeline(config=model_development_config)\n",
    "results = pipeline.train_models()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SentiScope-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
