{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\AI\\\\NLP\\\\HandsOn\\\\sentiment-analysis'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"../\")\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Union, Optional\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class ModelDevelopmentConfig:\n",
    "    root_dir: Path\n",
    "    data_files_path: Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SentiScope.constants import (CONFIG_FILE_PATH,\n",
    "                                  PARAMS_FILE_PATH)\n",
    "from SentiScope.utils.file_utils import (create_directories,\n",
    "                                            get_size)\n",
    "from SentiScope.utils.config_utils import (read_yaml,\n",
    "                                           Settings,\n",
    "                                           get_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        create_directories([self.config.artifacts_root])\n",
    "        \n",
    "    def get_latest_report(self) -> Dict:\n",
    "        \"\"\"Locate the latest metadata.json file based on the timestamp folder.\"\"\"\n",
    "        config = self.config.feature_transformation\n",
    "        profiling_dir = Path(config.root_dir)\n",
    "\n",
    "        # Get all subdirectories in data_profiling\n",
    "        timestamp_dirs = [d for d in profiling_dir.iterdir() if d.is_dir()]\n",
    "        \n",
    "        if not timestamp_dirs:\n",
    "            raise FileNotFoundError(\"No timestamp folders found in feature_transformation.\")\n",
    "\n",
    "        # Sort directories by name (assuming timestamp format)\n",
    "        latest_dir = sorted(timestamp_dirs, key=lambda x: x.name, reverse=True)[0]\n",
    "        metadata_path = latest_dir / \"metadata.json\"\n",
    "\n",
    "        if not metadata_path.exists():\n",
    "            raise FileNotFoundError(f\"metadata.json not found in {latest_dir}.\")\n",
    "\n",
    "        # Load the report.json file\n",
    "        with open(metadata_path, \"r\") as f:\n",
    "            report_data = json.load(f)\n",
    "\n",
    "        return report_data\n",
    "\n",
    "    def get_model_development_config(self) -> ModelDevelopmentConfig:\n",
    "        config = self.config.model_development\n",
    "        report_data = self.get_latest_report()\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        timestamp = report_data[\"timestamp\"]\n",
    "        # data_file_path = Path(str(config.data_file).format(timestamp=timestamp))\n",
    "        data_files_path = Path(config.data_files_path).joinpath(f\"{timestamp}\")\n",
    " \n",
    "\n",
    "        model_development_config = ModelDevelopmentConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            data_files_path=data_files_path,\n",
    "\n",
    "        )\n",
    "\n",
    "        return model_development_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BaseModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from typing import Dict, Any\n",
    "import numpy as np\n",
    "\n",
    "class BaseModel(ABC):\n",
    "    \"\"\"Abstract base class defining the interface for all models\"\"\"\n",
    "    \n",
    "    @abstractmethod\n",
    "    def train(self, X_train: Any, y_train: Any) -> None:\n",
    "        \"\"\"Train the model on the given data\"\"\"\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def predict(self, X: Any) -> np.ndarray:\n",
    "        \"\"\"Make predictions on new data\"\"\"\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def get_params(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get the model's current parameters\"\"\"\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def set_params(self, **params) -> None:\n",
    "        \"\"\"Set the model's parameters\"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mode Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "class SklearnModelWrapper(BaseModel):\n",
    "    \"\"\"Wrapper for scikit-learn models to conform to our interface\"\"\"\n",
    "    \n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "    \n",
    "    def train(self, X_train, y_train):\n",
    "        return self.model.fit(X_train, y_train)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)\n",
    "    \n",
    "    def get_params(self):\n",
    "        return self.model.get_params()\n",
    "    \n",
    "    def set_params(self, **params):\n",
    "        return self.model.set_params(**params)\n",
    "\n",
    "class LogisticRegressionModel(SklearnModelWrapper):\n",
    "    \"\"\"Logistic Regression implementation\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__(LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000))\n",
    "\n",
    "class SVMModel(SklearnModelWrapper):\n",
    "    \"\"\"Support Vector Machine implementation\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__(SVC(kernel='linear', probability=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Any, List\n",
    "from dataclasses import dataclass\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "from scipy.sparse import issparse\n",
    "\n",
    "@dataclass\n",
    "class TrainingResult:\n",
    "    \"\"\"Container for training results\"\"\"\n",
    "    model_name: str\n",
    "    metrics: Dict[str, float]\n",
    "    predictions: np.ndarray\n",
    "    parameters: Dict[str, Any]\n",
    "\n",
    "class TrainingManager:\n",
    "    \"\"\"Handles model training and evaluation\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.training_history: List[TrainingResult] = []\n",
    "    \n",
    "    def _validate_data_split(self, data_split):\n",
    "        \"\"\"Validate the data split dictionary\"\"\"\n",
    "        if not isinstance(data_split, dict):\n",
    "            raise TypeError(f\"data_split must be a dictionary, got {type(data_split)}\")\n",
    "            \n",
    "        required_keys = [\"X_train\", \"X_test\", \"y_train\", \"y_test\"]\n",
    "        \n",
    "        # Check all required keys exist\n",
    "        missing = [key for key in required_keys if key not in data_split]\n",
    "        if missing:\n",
    "            raise ValueError(f\"Missing required keys in data_split: {missing}\")\n",
    "        \n",
    "        # Check matching dimensions\n",
    "        n_train_samples = (data_split[\"X_train\"].shape[0] if not issparse(data_split[\"X_train\"]) \n",
    "                          else data_split[\"X_train\"].shape[0])\n",
    "        n_test_samples = (data_split[\"X_test\"].shape[0] if not issparse(data_split[\"X_test\"]) \n",
    "                         else data_split[\"X_test\"].shape[0])\n",
    "        \n",
    "        if n_train_samples != len(data_split[\"y_train\"]):\n",
    "            raise ValueError(f\"Mismatch in training set dimensions: \"\n",
    "                           f\"X_train has {n_train_samples} samples but y_train has {len(data_split['y_train'])} samples\")\n",
    "        \n",
    "        if n_test_samples != len(data_split[\"y_test\"]):\n",
    "            raise ValueError(f\"Mismatch in test set dimensions: \"\n",
    "                           f\"X_test has {n_test_samples} samples but y_test has {len(data_split['y_test'])} samples\")\n",
    "    \n",
    "    def train_and_evaluate(self, model, model_name: str, \n",
    "                          data_split) -> TrainingResult:\n",
    "        \"\"\"\n",
    "        Train a model and evaluate its performance\n",
    "        \n",
    "        Args:\n",
    "            model: A model object with train, predict, and get_params methods\n",
    "            model_name: String identifier for the model\n",
    "            data_split: Dictionary containing X_train, X_test, y_train, y_test\n",
    "            \n",
    "        Returns:\n",
    "            TrainingResult object containing metrics and predictions\n",
    "        \"\"\"\n",
    "        print(\"Data split keys:\", data_split.keys())\n",
    "        print(\"Data split types:\", {k: type(v) for k, v in data_split.items()})\n",
    "        print(\"Data split shapes:\", {\n",
    "            k: v.shape if hasattr(v, 'shape') else len(v) if hasattr(v, '__len__') else None \n",
    "            for k, v in data_split.items()\n",
    "    })\n",
    "        try:\n",
    "            # Validate the data split\n",
    "            self._validate_data_split(data_split)\n",
    "            \n",
    "            # Verify model has required methods\n",
    "            required_methods = ['train', 'predict', 'get_params']\n",
    "            for method in required_methods:\n",
    "                if not hasattr(model, method):\n",
    "                    raise AttributeError(f\"Model lacks required method: {method}\")\n",
    "            \n",
    "            # Train the model\n",
    "            print(f\"Training {model_name}...\")\n",
    "            model.train(data_split[\"X_train\"], data_split[\"y_train\"])\n",
    "            \n",
    "            # Make predictions\n",
    "            print(f\"Making predictions for {model_name}...\")\n",
    "            predictions = model.predict(data_split[\"X_test\"])\n",
    "            \n",
    "            # Calculate metrics\n",
    "            print(f\"Calculating metrics for {model_name}...\")\n",
    "            metrics = classification_report(\n",
    "                data_split[\"y_test\"], \n",
    "                predictions, \n",
    "                output_dict=True\n",
    "            )\n",
    "            \n",
    "            # Create and store result\n",
    "            result = TrainingResult(\n",
    "                model_name=model_name,\n",
    "                metrics=metrics,\n",
    "                predictions=predictions,\n",
    "                parameters=model.get_params()\n",
    "            )\n",
    "            self.training_history.append(result)\n",
    "            \n",
    "            print(f\"Successfully completed training and evaluation for {model_name}\")\n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error in train_and_evaluate for {model_name}: {str(e)}\")\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "class SentimentPipeline:\n",
    "    \"\"\"Coordinates all components of the sentiment analysis system\"\"\"\n",
    "    \n",
    "    def __init__(self, config: ModelDevelopmentConfig):\n",
    "        self.config = config\n",
    "        self.data_files_path = self.config.data_files_path\n",
    "        self.training_manager = TrainingManager()\n",
    "        self.models = {\n",
    "            'logistic_regression': LogisticRegressionModel()\n",
    "        }\n",
    "    \n",
    "    def prepare_data(self,):\n",
    "        \"\"\"\n",
    "        Load prepared data from artifacts and split it for training and testing.\n",
    "        \n",
    "        Args:\n",
    "            test_size (float): Size of the test split. Not used here since the data is already split.\n",
    "        \n",
    "        Returns:\n",
    "            tuple: x_train, x_test, y_train, y_test as NumPy arrays.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Construct paths to the data files\n",
    "            x_train_path = os.path.join(self.data_files_path, \"X_train.npy\")\n",
    "            x_test_path = os.path.join(self.data_files_path, \"X_test.npy\")\n",
    "            y_train_path = os.path.join(self.data_files_path, \"y_train.npy\")\n",
    "            y_test_path = os.path.join(self.data_files_path, \"y_test.npy\")\n",
    "\n",
    "            # Load the data\n",
    "            X_train_npy = np.load(x_train_path, allow_pickle=True)\n",
    "            X_test_npy = np.load(x_test_path, allow_pickle=True)\n",
    "            y_train = np.load(y_train_path, allow_pickle=True)\n",
    "            y_test = np.load(y_test_path, allow_pickle=True)\n",
    "            \n",
    "            # Convert the dense array to a sparse matrix (e.g., CSR format)\n",
    "            X_train_sparce = sparse.csr_matrix(X_train_npy.all())\n",
    "            X_test_sparce = sparse.csr_matrix(X_test_npy.all())\n",
    "\n",
    "            print(\"Data successfully loaded.\")\n",
    "            return X_train_sparce, X_test_sparce, y_train, y_test\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading data: {e}\")\n",
    "            raise e\n",
    "    \n",
    "    def train_models(self):\n",
    "        \"\"\"Train all registered models\"\"\"\n",
    "        results = {}\n",
    "        x_train, x_test, y_train, y_test = self.prepare_data()\n",
    "        data_split = {\n",
    "            \"X_train\": x_train,\n",
    "            \"X_test\": x_test,\n",
    "            \"y_train\": y_train,\n",
    "            \"y_test\": y_test\n",
    "        }\n",
    "        \n",
    "        for name, model in self.models.items():\n",
    "            results[name] = self.training_manager.train_and_evaluate(\n",
    "                model, name, data_split\n",
    "            )\n",
    "        \n",
    "        return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-01-12 06:37:33,151: INFO: config_utils: yaml file: config\\config.yaml loaded successfully]\n",
      "[2025-01-12 06:37:33,153: INFO: config_utils: yaml file: params.yaml loaded successfully]\n",
      "[2025-01-12 06:37:33,154: INFO: file_utils: created directory at: artifacts]\n",
      "[2025-01-12 06:37:33,157: INFO: file_utils: created directory at: artifacts/model_development]\n",
      "Data successfully loaded.\n",
      "Data split keys: dict_keys(['X_train', 'X_test', 'y_train', 'y_test'])\n",
      "Data split types: {'X_train': <class 'scipy.sparse._csr.csr_matrix'>, 'X_test': <class 'scipy.sparse._csr.csr_matrix'>, 'y_train': <class 'numpy.ndarray'>, 'y_test': <class 'numpy.ndarray'>}\n",
      "Data split shapes: {'X_train': (175435, 5000), 'X_test': (43859, 5000), 'y_train': (175435,), 'y_test': (43859,)}\n",
      "Training logistic_regression...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\AI\\NLP\\HandsOn\\sentiment-analysis\\SentiScope-env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions for logistic_regression...\n",
      "Calculating metrics for logistic_regression...\n",
      "Successfully completed training and evaluation for logistic_regression\n",
      "{'logistic_regression': TrainingResult(model_name='logistic_regression', metrics={'0': {'precision': 0.8866193144218467, 'recall': 0.9321860939746741, 'f1-score': 0.9088319088319088, 'support': 21559.0}, '1': {'precision': 0.8566114933978055, 'recall': 0.8223531512229959, 'f1-score': 0.8391328110766989, 'support': 11202.0}, '2': {'precision': 0.7506227246598965, 'recall': 0.7059830600108128, 'f1-score': 0.7276188707280832, 'support': 11098.0}, 'accuracy': 0.846895734056864, 'macro avg': {'precision': 0.8312845108265162, 'recall': 0.8201741017361609, 'f1-score': 0.8251945302122303, 'support': 43859.0}, 'weighted avg': {'precision': 0.844542710662312, 'recall': 0.846895734056864, 'f1-score': 0.8451762944784097, 'support': 43859.0}}, predictions=array([0, 2, 1, ..., 2, 0, 2]), parameters={'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False})}\n"
     ]
    }
   ],
   "source": [
    "config = ConfigurationManager()\n",
    "model_development_config = config.get_model_development_config()\n",
    "pipeline = SentimentPipeline(config=model_development_config)\n",
    "results = pipeline.train_models()\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SentiScope-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
