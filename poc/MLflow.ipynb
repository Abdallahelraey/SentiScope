{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\AI\\\\NLP\\\\HandsOn\\\\sentiment-analysis'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"../\")\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Optional, Dict\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class MLflowConfig:\n",
    "    root_dir: Path\n",
    "    experiment_name: str\n",
    "    run_name: str\n",
    "    tracking_uri: str\n",
    "    artifact_location: Optional[str]\n",
    "    default_tags: Dict[str, str]\n",
    "    dynamic_tags: Dict[str, bool]\n",
    "    logging: Dict[str, bool]\n",
    "    basemodel: Dict[str, str]\n",
    "    advancedmodel: Dict[str, str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SentiScope.constants import (CONFIG_FILE_PATH,\n",
    "                                  PARAMS_FILE_PATH)\n",
    "from SentiScope.utils.file_utils import (create_directories,\n",
    "                                            get_size)\n",
    "from SentiScope.utils.config_utils import (read_yaml,\n",
    "                                           Settings,\n",
    "                                           get_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath=CONFIG_FILE_PATH,\n",
    "        params_filepath=PARAMS_FILE_PATH,\n",
    "    ):\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_mlflow_config(self) -> MLflowConfig:\n",
    "        config = self.config.mlflow\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        # Prepare the MLflow configuration object\n",
    "        mlflow_config = MLflowConfig(\n",
    "            root_dir = config.root_dir,\n",
    "            experiment_name=config.experiment.name,\n",
    "            run_name = config.experiment.run,\n",
    "            tracking_uri=config.experiment.tracking_uri,\n",
    "            artifact_location=config.experiment.artifact_location,  \n",
    "            default_tags=config.default_tags,\n",
    "            dynamic_tags=config.dynamic_tags,\n",
    "            logging=config.logging,\n",
    "            basemodel=config.basemodel,\n",
    "            advancedmodel=config.advancedmodel,\n",
    "        )\n",
    "\n",
    "        return mlflow_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from SentiScope.logging import logger\n",
    "from typing import Any, Dict, Optional\n",
    "from functools import wraps\n",
    "from SentiScope.entity import MLflowConfig\n",
    "\n",
    "class MLflowTracker:\n",
    "    \"\"\"\n",
    "    A modular MLflow tracking component that can be imported and used across different modules\n",
    "    without interfering with their core logic.\n",
    "    \"\"\"\n",
    "    def __init__(self, config: MLflowConfig):\n",
    "        self.config = config\n",
    "        self.experiment_name = self.config.experiment_name\n",
    "        self.run_name = self.config.run_name\n",
    "        self.tracking_uri = self.config.tracking_uri\n",
    "        self.run = None\n",
    "        \n",
    "        try:\n",
    "            if self.tracking_uri:\n",
    "                mlflow.set_tracking_uri(self.tracking_uri)\n",
    "                logger.info(f\"Setting MLflow tracking URI to: {self.tracking_uri}\")\n",
    "                \n",
    "                # Test connection before proceeding\n",
    "                self._test_connection()\n",
    "            \n",
    "            # Get or create experiment\n",
    "            experiment = mlflow.get_experiment_by_name(self.experiment_name)\n",
    "            if experiment is not None:\n",
    "                self.experiment_id = experiment.experiment_id\n",
    "                logger.info(f\"Found existing experiment: {self.experiment_name} with ID: {self.experiment_id}\")\n",
    "            else:\n",
    "                self.experiment_id = mlflow.create_experiment(self.experiment_name)\n",
    "                logger.info(f\"Created new experiment: {self.experiment_name} with ID: {self.experiment_id}\")\n",
    "\n",
    "        except ConnectionError as e:\n",
    "            logger.error(f\"Failed to connect to MLflow tracking server at {self.tracking_uri}: {str(e)}\")\n",
    "            raise\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error initializing MLflow tracker: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def _test_connection(self) -> bool:\n",
    "        \"\"\"Test connection to MLflow server\"\"\"\n",
    "        try:\n",
    "            mlflow.get_tracking_uri()\n",
    "            # Try to list experiments as a connection test\n",
    "            mlflow.search_experiments()\n",
    "            logger.info(\"Successfully connected to MLflow server\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            raise ConnectionError(f\"Cannot connect to MLflow server: {str(e)}\")\n",
    "\n",
    "    def start_run(self, run_name: str, nested: bool = False):\n",
    "        \"\"\"Start a new MLflow run if none is active\"\"\"\n",
    "        if run_name:\n",
    "            self.run_name = run_name\n",
    "        try:\n",
    "            self.run = mlflow.start_run(\n",
    "                experiment_id=self.experiment_id, \n",
    "                run_name=self.run_name,\n",
    "                nested=nested  # Add nested parameter support\n",
    "            )\n",
    "            logger.info(f\"Started new MLflow run with ID: {self.run.info.run_id}\")\n",
    "            return self.run.info.run_id\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error starting MLflow run: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def log_params(self, params: dict):\n",
    "        \"\"\"Log parameters to MLflow\"\"\"\n",
    "        try:\n",
    "            if self.run is None:\n",
    "                raise RuntimeError(\"No active MLflow run. Call start_run() first.\")\n",
    "            mlflow.log_params(params)\n",
    "            logger.debug(f\"Logged parameters: {params}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error logging parameters: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def log_metrics(self, metrics: dict):\n",
    "        \"\"\"Log metrics to MLflow\"\"\"\n",
    "        try:\n",
    "            if self.run is None:\n",
    "                raise RuntimeError(\"No active MLflow run. Call start_run() first.\")\n",
    "            mlflow.log_metrics(metrics)\n",
    "            logger.debug(f\"Logged metrics: {metrics}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error logging metrics: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def log_model(self, model: Any, artifact_path: str):\n",
    "        \"\"\"Log ML model to MLflow\"\"\"\n",
    "        try:\n",
    "            if self.run is None:\n",
    "                raise RuntimeError(\"No active MLflow run. Call start_run() first.\")\n",
    "            mlflow.sklearn.log_model(sk_model=model, artifact_path=artifact_path)\n",
    "            logger.info(f\"Logged model to artifact path: {artifact_path}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error logging model: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def log_artifact(self, artifact_path: str, destination_path: str = None):\n",
    "        \"\"\"Log artifact to MLflow\"\"\"\n",
    "        try:\n",
    "            if self.run is None:\n",
    "                raise RuntimeError(\"No active MLflow run. Call start_run() first.\")\n",
    "            mlflow.log_artifact(artifact_path, destination_path)\n",
    "            logger.info(f\"Logged artifact from {artifact_path} to {destination_path or 'default path'}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error logging artifact: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def end_run(self):\n",
    "        \"\"\"End the current MLflow run\"\"\"\n",
    "        try:\n",
    "            if self.run:\n",
    "                mlflow.end_run()\n",
    "                logger.info(\"Ended MLflow run\")\n",
    "                self.run = None\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error ending MLflow run: {str(e)}\")\n",
    "            raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataIngestion:\n",
    "    def __init__(self, mlflow_tracker: MLflowTracker):\n",
    "        self.mlflow_tracker = mlflow_tracker\n",
    "        self.mlflow_tracker.start_run(run_name=\"Data_Ingestion\",nested=True)\n",
    "    def ingest_data(self, source: str) -> dict:\n",
    "        # Your existing ingestion logic here\n",
    "        metrics = {\n",
    "            'rows_ingested': 1000,\n",
    "            'ingestion_time': 10.5\n",
    "        }\n",
    "        # Log metrics instead of params\n",
    "        self.mlflow_tracker.log_metrics(metrics)\n",
    "        return {'metrics': metrics, 'data': 'ingested_data'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-01-19 16:06:45,289: INFO: config_utils: yaml file: config\\config.yaml loaded successfully]\n",
      "[2025-01-19 16:06:45,291: INFO: config_utils: yaml file: params.yaml loaded successfully]\n",
      "[2025-01-19 16:06:45,293: INFO: file_utils: created directory at: artifacts]\n",
      "[2025-01-19 16:06:45,294: INFO: file_utils: created directory at: artifacts/mlflow_tracking]\n",
      "[2025-01-19 16:06:45,295: INFO: 23541907: Setting MLflow tracking URI to: http://localhost:5000]\n",
      "[2025-01-19 16:06:47,352: INFO: 23541907: Successfully connected to MLflow server]\n",
      "[2025-01-19 16:06:47,361: INFO: 23541907: Found existing experiment: sentiment_analysis_pipeline with ID: 854231226268693672]\n",
      "[2025-01-19 16:06:47,619: INFO: 23541907: Started new MLflow run with ID: efe8a705ae624f2893f6504a3e8b907f]\n",
      "[2025-01-19 16:06:47,674: INFO: 23541907: Started new MLflow run with ID: 4631619513f64ff18ab7ea92e7f3a3c4]\n"
     ]
    }
   ],
   "source": [
    "# Main execution\n",
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    mlflow_config = config.get_mlflow_config() \n",
    "    mlflow_tracker = MLflowTracker(config=mlflow_config)\n",
    "    mlflow_tracker.start_run(\"MainPipeline\")\n",
    "    data_ingestion = DataIngestion(mlflow_tracker)  \n",
    "    dataframe = data_ingestion.ingest_data(  # Fixed variable naming convention\n",
    "        source=r\"D:\\AI\\NLP\\HandsOn\\sentiment-analysis\\artifacts\\feature_transformation\\20250117_082011\\test_split.csv\"\n",
    "    )\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-01-19 16:07:44,528: INFO: 23541907: Started new MLflow run with ID: 43a19df81f2d461eb68b81b10fb5d105]\n"
     ]
    }
   ],
   "source": [
    "data_ingestion = DataIngestion(mlflow_tracker)  \n",
    "dataframe = data_ingestion.ingest_data(  # Fixed variable naming convention\n",
    "    source=r\"D:\\AI\\NLP\\HandsOn\\sentiment-analysis\\artifacts\\feature_transformation\\20250117_082011\\test_split.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run Data_Ingestion at: http://localhost:5000/#/experiments/854231226268693672/runs/43a19df81f2d461eb68b81b10fb5d105\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/854231226268693672\n",
      "[2025-01-19 16:08:53,826: INFO: 23541907: Ended MLflow run]\n"
     ]
    }
   ],
   "source": [
    "mlflow_tracker.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Runnign Commands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`mlflow server --host 127.0.0.1 --port 5000`\n",
    "`mlflow.set_tracking_uri(\"file:///path/to/your/mlruns\")`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### https://mlflow.org/docs/latest/getting-started/registering-first-model/step1-register-model.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SentiScope-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
